---
event_name: "Deep Dive: Assistant Training & Automation Workflow"
fireflies_id: 01JQN8YXGY6XMC7GRC7FSK8HZ2
fireflies_url: https://app.fireflies.ai/view/01JQN8YXGY6XMC7GRC7FSK8HZ2
date: 2025-04-02T04:00:00.000Z
duration: 78 minutes
participants: Chris York, Eliot Gattegno
---

Chris York (4:26):
This meeting is being recorded.

Chris York (4:56):
Hey, what's going on?

Eliot Gattegno (4:58):
Hey, Chris. How's Bali?

Chris York (5:00):
It's good. Can't complain.

Eliot Gattegno (5:02):
Where. Where exactly are you on the island?

Chris York (5:05):
Changu.

Eliot Gattegno (5:07):
Where? Like, geographically, where is that?

Chris York (5:11):
It's on the south coast. It's about an hour northwest from Denpasar.

Eliot Gattegno (5:20):
Okay. Okay.

Chris York (5:23):
And it's an hour south of Ubud, if you can. Ubud?

Eliot Gattegno (5:25):
Yeah. I used to get to go, like, kind of frequently because it was a pretty quick flight for me when I was living in Shanghai.

Eliot Gattegno (5:35):
Yeah.

Chris York (5:35):
Yeah. And then I used to live in Shanghai too, by the way.

Eliot Gattegno (5:38):
Oh, I didn't know that. How long were you there? When were you there?

Chris York (5:41):
I studied it for a semester.

Eliot Gattegno (5:46):
When you were in undergrad?

Eliot Gattegno (5:48):
Yeah.

Eliot Gattegno (5:50):
Cool. Cool. Yeah, it is. Well, it's. It's very different now, put it that way.

Chris York (5:56):
Yeah, it is.

Eliot Gattegno (5:57):
And so I have some friends. I mean, I left NYU in 2018, and I have some friends that stayed. And, like, even through the pandemic, they stayed there. Like, one of them was, like, one of those, like, some of their, like, posting daily, like, went viral on the. The conditions and all of the stuff because they, like, wrote for the Financial Times and stuff like that as an economist. And then, like, they became really well known for, like, posting their pandemic videos as a, you know, foreigner living in Shanghai through it. So pretty crazy. But, yeah, it seems like it's a much less fun place to be these days, so.

Chris York (6:34):
So anyway, yeah, I'm not that hyped to go back anytime soon.

Eliot Gattegno (6:41):
Yeah, I wouldn't. I wouldn't imagine there's, like, any reason, like, all of the. All of the fun stuff just seems to be totally gone. And so. Yeah, just still got Taipei, though. We could do that, I guess. And so, like, maybe for a few more months or years, we'll see that it's. It stays the way that it is. But good food. I guess I'd go to Taipei for food for sure. Let's. Is Carlos joining us or is it just us?

Chris York (7:13):
I don't think Carlos is joining. Also, it's his birthday, and he usually doesn't sign on for another couple hours, so.

Eliot Gattegno (7:20):
Oh, cool. Well, happy birthday to Carlos, if he's watching the recording. Well, I wasn't sure. I mean, there. There's a couple of points of departure, but was there anything that you wanted to go into or you were most kind of excited to share? Maybe just start.

Chris York (7:37):
Not really. Whatever is most useful to you.

Eliot Gattegno (7:42):
Cool. I guess. Trying to think. So. One thing that I want to do or want to do. We're going to do this starting this quarter because it is Q2 as of today is we're going to do like a series of. Oh, am I frozen, Chris?

Chris York (8:04):
Slightly. Why don't I turn off my video? Because maybe the Balinese wi fi would do better with the audio if I turn it off.

Eliot Gattegno (8:13):
No, it's my. I think it's my actual laptop. Hold on one second.

Eliot Gattegno (8:34):
Can you hear me?

Chris York (8:35):
Yeah, I hear you.

Eliot Gattegno (8:38):
So you have totally disappeared. Let me.

Chris York (8:41):
Yeah, I turned off, I turned off the video just because I thought it might be stressing the connection, but I can turn it back on.

Eliot Gattegno (8:46):
Oh no, I mean like the Zoom app like totally disappeared. So I can hear you. But Zoom app is good. So let me just sign off. I'll be right back.

Chris York (8:54):
Okay.

Eliot Gattegno (9:41):
Cool. Yeah, it's super weird. And then it shows that I'm still. My other one was still there. That's never happened before. Like, literally zoom just disappeared from the screen. But I could still hear you speaking. So anyway, what I was, what I was saying is this month in this quarter, we are going to start this series of kind of client and XP co training sessions. And I wanted to do them on, you know, hopefully like really advanced delegation practices and things that would be like, you know, you know, hopefully really empowered with like, lots of AI tools. So like kind of helping people like, you know, really build kind of much more advanced relationships like you have with Carlos and others. And so there would be training that we'd be providing for the xps in advance of those sessions so they can hopefully really show up and impress their clients. And then there would also be different things for their clients as well. And so like, hopefully the clients would be able to lean much more into their EAs than they currently are. And then we'd be able to show them how to do stuff and so on and so forth. So like, for example, like I've turned one of my EAs basically into a kind of like advanced PhD student assistant professor and they're like running experimental work and like, so like you'd appreciate. Yeah, like I'll just like share, share with you what they're doing because you, you'd obviously get it one quick second. You know, it's like.

Chris York (11:31):
I'll just toss.

Eliot Gattegno (11:31):
This over in, in Zoom, they're doing experiments like this. Oh wow, my Internet's terrible.

Chris York (11:48):
Is it in the chat or where am I supposed to be looking?

Eliot Gattegno (11:51):
No, it'll be in the chat. It's just. Yeah, my Internet's super slow, so. Yeah, so like, so this is like 90 something, 95% done by one of my XPs. And so now we're going to have them, you know, they've learned how to do this. They've, they've taught like, taught them how to do this. It took like you know, a month to do like the first thing, learn how to do experiment design, like, you know, learn how to use. Do you do this like actually conduct the research for the cloud research, et cetera. And then they can go now they, now they did this like they did this one in a week. Now they're going to try two this week and then like, you know, so like like that's a pretty extraordinary output for an XP to be able to do but totally capable. And then it gets you know, just kind of like edited, tweaked and working on a series of these for some peer reviewed papers and then other stuff they're working on. So like, you know, that's like an example of like, you know, in, in something that I'm working on that's like I would say like next level delegation practices. Yeah, I think like the stuff that you're doing with Carlos related to AI, whether it's being with like, you know, some of the apps and stuff that Jonathan was, was sharing. I know that One of my XPs like built a, like a, a website that we had been wanting to do for Matisse for the college in like five minutes that was better than like something that we had previously paid $10,000 for. So it, this is amazing.

Chris York (13:30):
And so like yeah, I mean somebody would easily pay Anne 10 to 20 grand for the iOS app that she made, you know, and so like that's.

Eliot Gattegno (13:38):
The type of thing like I'd love to get different, I'd like love to get your take on like number one, like what is the list just like most basically from a most basic point of view of all the kind of the tools that we should be basically training up this like kind of elite AI, I think we're calling it like AI Insider or something like that. We'll figure it out from a client perspective. So I want to get like a whole list of tools but then also like what's great is really specific use cases and then how like basically like workflows, use cases, so on and so forth, like at the most advanced level that that's out there. And so like if we can put together like basically a series of these things on like very, very high level use cases, we'll invite select clients and we'll have select EAs doing and we'll do these trainings to them together and then really start to get building things up. So that the main thing that was on my mind and when I saw what Jonathan was texting me about, I was just like, oh yeah, I'd love to talk with Chris about this and take a look and see what's going on there. So that's, that's what's on my mind.

Chris York (14:44):
Yeah, that makes sense. And I mean, I think a lot of it is how to use the, the different AIs and like which models and how to prompt them and things like that. Because, like, for example, looking at the thing you just shared with me, pretty commonly known that most of the LLMs, they can't do math, but they could write a Python program or something with R that can do your anova, right? And if the EA wasn't trained on that, they might say, hey chatgpt, like here's some stats, like do the calculations. It can't do that, but it can write the program that does it. It can use matplotlib or whatever you're using for the graphs and it can put stuff out that like you said, is on par with, you know, median, postdoc or, you know, whatever you want to quantify it. And then the same thing with Anne, right, where, you know, Anne hasn't built an app before. She's not only not a developer, she's not a pm. And just giving her like a little bit of like the terminology and say, hey, you can prompt the reasoning models to help you write the prd and then you prompt like these different models to help you write the code. Use Lovable, you export it to cursor. Use bolt new, export it to cursor. Little tricks like that I think are helpful. One of the issues is the models change a lot. The right one to use is going to change probably by the time you publish the material. Although, like, there's different classes of models, even those might be going away. Like OpenAI has sort of said, like there won't be a distinction between reasoning models and regular chat models in the future because the reasoning will kind of be built in and as the compute gets faster, then you're going to have that. So I think anything you do on AI, there's got to be some sort of rapid upgrade, you know, component to those materials. Luckily, the AI can probably help you with that, but I think that's like the big thing with Carlos in particular and also, and to an extent, like with her graphic assets that she made for the game or for the app using workflow automation platforms. We really like N8N because Zapier was getting out of control, we were paying almost two grand for the automations we're doing. And N8N has the two advantages of one, aside from being cheaper, you can export and import workflows, which is very hard to do if not impossible to do on Zapier unless you're all in the same enterprise account, which is not going to be the case for, you know, if you were a client and I were a client, we're not in the same enterprise Athena Zapier account. Right. And the other thing is it's just more purpose built for AI and you can self host it so it's effectively free. Right. I pay like $5 a month and I automate probably 10 times as much as Zapier was charging me almost 2 grand a month for. So whether or not we like N8N or we like make.com or whatever solution, workflow automation is a really important thing for EAs to learn because then they're essentially delegating an automatable process that the AI can play a part in. Right? So like for example, with the game assets, the AI was writing a prompt for each item or character or achievement or graphic from a Google sheet and then writing that prompt, sending that prompt to a image generation AI and saving it to a Google Drive, right? And that's the sort of thinking and ability again tool agnostic that it's really important for the EAs to have because the more stuff that they can automate to a, you know, a rules based system with or without an AI agent in the loop with it, then the more they can do, the more creative and difficult stuff, whether it's an iOS app or whether it's, you know, putting together the stuff for research for an experiment or things that you wouldn't fully delegate to an AI or you would want to co perform with the top level ones like the ones of the world and things like that. So I think workflow automation is really, really key. If you're always the one typing the prompt into ChatGPT or whatever, like that's just not scalable. Like there's only so many prompts you can type in a day. Whereas if it's firing every time you get an email, or if it's firing every time a file is saved to your Google Drive folder, or every time you download an ebook file, or running once for every row in a spreadsheet, then that really like uncaps how much people can perform right So I think that's really key. I think some of the prompting stuff is really important. Honestly, like with Anne, I didn't really teach her a lot about coding. I taught her a little bit about product. Like, here's what a PRD is. This is how you manage a real engineer and how it would translate to managing an AI that does engineering. It was really more about teaching her prompting than it was anything else. And it's like, when do you use which models for what and how do you unblock yourself on things? Because, you know, if she's going to come to me and ask me a nuanced question about REACT native, I can't answer that question. Right. My, my degree is in psychological science, not computer science. So she has to be able to go and talk to an AI and get the prompt for the other AI. Right. And that's a skill that's very translatable to other forms of endeavor. Right. Whether she's working on a style guide, if she was going to generate an essay or a social media post or whatever the case may be, or how to find good quality examples. A lot of the rules that are in cursor that help make the AIs perform according to best practices for coding. You know, finding like those examples and putting them in the prompt, or finding good examples of prompts online for usage with the image generation AIs, or example prompts where people have used it for, you know, creating programs that do stats for you for your papers, for example. Right. Those are all things where it's sort of like a meta skill as opposed to like, how do I do this? It's like, how do I find the inputs to give to the AI to help me do this, even if I don't fully understand what I'm doing? Like coding React, right?

Eliot Gattegno (20:28):
Yep.

Eliot Gattegno (20:30):
Yeah, yeah.

Eliot Gattegno (20:35):
So like, what, just how did, how did you get Ann? So you were just, she was, she was matched with you and she was just like a total novice at this stuff. And then was it you working with her or Carlos working with her to kind of coach her up more on these different things?

Chris York (20:52):
So as I understand it, Ann was with Athena for a long time. I think she had three clients before me, but none of them had her do anything related to AI at all or workflow automation or anything like that. She got some stuff from Carlos about prompting probably. I think they talked to one another a little bit. As far as like cursor. Carlos had not used cursor yet. He has now, but Anne used it before him. So I just answered her questions or gave or sent her like links or YouTube videos that I thought had good insight or cursive rules that I thought had good insights. Or, you know, I would look at her conversation with AI and be like, well, you prompted it this way, but if you prompted it this other way or if you ask this model for a prompt to give it, then you know, it would probably have better output a lot of it. I think there are two things that are really interesting. You know, she didn't really learn that much about coding. She learned a lot about how to delegate to an AI. Some people are calling this software being a software composer or a software orchestrator rather than a software developer, right? And even though she's like 10x her ability to coerce good application code out of the AI, she doesn't necessarily have a better understanding of react like 10 times better than she had at the outset. So it was really more about delegation and prompting and some of these like adjacent skills rather than pure engineering. The things that seemed to bottleneck her were one process related stuff where it was like, oh, I can use this model to make a prompt for a PRD and then I can ask the model to use that as context to write little feature specs for each individual feature and then use a different model for the implementation or knowing which AIs to use for which thing. So a lot of it was process, not only process of using AI, but also just process of like product management, software development. How do you do one thing at a time, make sure that you test it, you know, before you move on to the next thing so you don't break something and then have to roll yourself back, right? You lose hours of work if you don't use GitHub and check in your code, right? And then the second thing was terminology, because with a lot of these things, and this is not exclusively limited to software development, right? There are certain terminology where if you know the right word, it's kind of like a magic spell. And then the AI knows what to do, right? So in the case of the React app, for example, like sometimes the application was laggy when you would do something because it was waiting to write to the database. So you would say, hey, update the local state immediately, optimistically, and then have that occur instantly while the API is running in the background to write to the database, right? And there's like certain terminology. If you use it, the AI gets it right on the first try. But if you kind of vaguely describe it, if you're a layperson and don't know Any of the terminology, then it is much less likely to do what you want. It's the same thing, right? Whereas, like, if somebody who had no background in academics or publishing papers or statistics, like, if you ask them to get the AI to produce something similar to an example paper, it would probably not be good. Whereas if they knew to say, like, okay, write a Python program that does this, gets the data from here and transforms it this way, or does, you know, the chi squared for this thing or the pearson, you know, then it's much more likely to come out the way you want. If you can't use the right terminology, it's going to make you a lot less adept at using the AI.

Eliot Gattegno (24:19):
Right, yeah. And then, so, so I'm clear, like, so you're providing her and you're, you're still coaching her on the terminology pieces of things at this time.

Chris York (24:31):
Only if she gets into a death loop in cursor. Right? So a lot of the time she gets the right terminology from say the 01 or 03 mini high or cloud sonnet 3.7, and then she can give it to cursor and it does what it needs. Once in a while she's like, hey, the thing isn't working. It's not saving to the database. I've tried five different prompts, I don't know what it is. And I'm like, okay, the word that you're looking for is this, you know, like this is the software term for the thing that you're trying to do. So sometimes I would give it to her. A lot of the times she gets it from a different model. Right. But the, the important thing is, like, there is like kind of like a terminology or scaffolding that you need to get the most out of the AIs, and it tends to be domain specific.

Eliot Gattegno (25:16):
Yeah, yeah, no, makes sense. So like on the workflow automation stuff. Yeah, I get that Everything, you know, basically goes stale as soon as it's kind of published. So we would need to have training materials refreshed, you know, pretty much on a weekly basis.

Chris York (25:33):
The concepts are the same. Right? Like, so whether you're using Zapier or you're using N8N or you're using anything. Like the concepts of how do you build a workflow, automate it. What parts do you use? AI, what parts do you use? Human in the loop, those are not changing. Basically. Maybe the capability of the AI in the loop changes, but none of the other stuff changes. Like, stuff like the features AP has or the platforms, they evolve a little Bit what the AI can do or cannot do evolves a little bit. Which AI used for what changes very frequently. But I mean, building, like recognizing when you're doing a workflow that should be automated or can be automated with or without AI, that is like a key, key skill, because otherwise people are just going to be doing busy work and not get the most out of what they're doing. And another great example of this is with Carlos. When we were working on something for the manifesto, we got all these books, biographies about historic figures in different fields, like Walt Disney, Cicero, whoever you got, and built a workflow that had an AI, like break everything into a single chapter, looked for examples of delegating or leveraging an assistant, and extracted all the quotes, right? And it read the equivalent of like 20 years worth of reading and analysis in like an hour. And he would not have necessarily come up with that workflow at that point, but he was able to build it. Right? So I think the two separate skills are like, how do you build the workflow? You know, can it involve AI, how much do you trust the AI to do, how you check its work, et cetera. And then recognizing when you're doing something that could be sort of the way we think about it is an assembly line for knowledge work, right? Which is kind of what the workflows or the AIs enable.

Eliot Gattegno (27:36):
And then I guess what would also be helpful, and we don't need to go over it now, but if you could have maybe Carlos send, and it could also be from you, the highest utility workflows that you have automated and that you think might be generalizable to our population.

Chris York (27:54):
Oh, that's easy. Email autodelegator. The AI that reads all my emails and then creates a task in the task manager for Carlos or for the AI or for Ann to do. Easy. I mean, it runs hundreds of times a day. It's great because it avoids anything being dropped where it's like, oh, you know, the email got read, but nobody created a task for it and it didn't get followed up. It relates exactly to Athena's core business. It's a problem everybody has. And a lot of the times the AI finds ways to delegate. The client wouldn't delegate themselves. Right. Or might be reluctant to. So it kind of makes it the default behavior, which, you know, in behavioral psychology is very important. So what's great is a lot of the time, you know, by the time I check my email, it's already been done, you know, and that's like, that's the win Condition for delegation generally. Right?

Eliot Gattegno (28:23):
Yeah. And then what else? Like what would be. If we were going to do a few like we, we would want to have like. Cause like I could totally imagine email auto delegator being one session if I were to basically if I want to like kind of curate the AI insiders thing. Like I think the stuff like the app building that you were doing, like that's, that's super interesting and people might be like, hey yeah, if my EA can be develop an app in a month using this and so on and so forth, might be, that might be high utility. But wondering what else would be like top of mind for you.

Chris York (28:58):
Yeah, I mean honestly, I think the auto delegate, it's a great example of a workflow that's high utility. I think frankly Hater or somebody in the engineering team should just build that as something that the clients can turn on and off. I don't think EPA should build it for their client. Maybe there's different prompts on how to delegate or what to delegate. But yeah, I mean we can go look at the workflows. We have a couple of hundred, I think around 500. So. And Carlos can explain most of them. They're very different. Some of them are very AI forward, Some of them are just straight up rules based. So there should be a good mix of examples in there. The app stuff, I mean, I don't know to what extent people need their EAs building apps. It is cool that they can and there are some best practices that we've learned. So it might as well be like something on the curriculum. I think the other thing is it's really cool if they can build something in the training and then share it with people afterwards because it kind of lets you course correct what the ceiling on your capabilities is. And it's just like a fun thing to do. Right. And given the advancement of things like bolts or lovable and cursor to a lesser extent, it's a little bit more advanced but you know, allows you to do more powerful stuff. The, the ceiling has been raised on this stuff and it doesn't take you long to do it. Carlos's app took two days and app was like incredibly ambitious and took two weeks. And I think it's really interesting as a, a tool that also like serves to create like kind of a sense of empowerment or, or things like that in addition to like a skill that can be applied to create value directly. Right?

Eliot Gattegno (30:47):
Yeah. And like what, what I'd love to have is, you know, we use circle for like our internal Community and knowledge, kind of sharing stuff. And so the EAs have thousands and thousands of. We have artifacts which are like, just like the raw assets, guides or like how to. That we've divided up to how many minutes they take and then, and then. So like, I'd love to like right now we have thousands and thousands of artifacts, you know, hundreds, hundreds of guides and different things that the EAs are creating.

Chris York (31:23):
And the great thing about N8N is they can export every single workflow as an artifact, as a JSON file that anyone can upload and remix, which you can't do in Zapier. Right. So those workflows themselves, whether it's an example or whatever, can, can be made into an artifact.

Eliot Gattegno (31:39):
Yeah, that would be like, it'd be amazing to kind of get what you think, what's, what's shareable from Carlos and kind of get started with, with, with that sort of activity. Because this is like. Yeah, I mean it, I think that's where we need to go now. We also need to figure out the, like, which, you know, the challenges around how to get the clients to actually do this stuff and lean into it. So that's where like also the, the training goes. I mean, you would not believe the percentage of clients that don't give their EA's email access like at all.

Chris York (32:11):
Oh, I would believe it because I, I interviewed like 50 clients and I found that out directly.

Eliot Gattegno (32:16):
So which is just like, I mean it's like stuff like that, that's just totally, just opening up what you're, what you're saying.

Chris York (32:23):
This is just an example of a workflow. This is one that we created for Jonathan because he, he asked for a workflow that would look at all the trending projects on GitHub and then review with AI which ones are from like new startups or up and coming developers or AI researchers and figure out like which ones are venture investable or interesting in that regard. This took like 30 minutes to build. Right. And if somebody needed something like that, you export it as a JSON file, you upload it to circle, you put some instructions and they can take it and do whatever they want with it. Right. They could change the criteria that they use to do it. Let's say the, the client is a software developer as opposed to a venture capitalist. It could do a completely different analysis. Right. In terms of the AI prompt and it could save it to a CRM or it could save it to Google Drive, or it could send them a slack message with a slack bot. Right. So I, I think this is a great thing and it's really easy to operationalize because of the export of the JSON files.

Eliot Gattegno (33:23):
So like, advanced research also seems like just a general, really, well, like, really widely applicable area. So like, for me, like for example, right now, and I'm sure that there's a way to do this. I don't know, I was just reading a New York Times article about this like 7,500 acre ranch in Pennsylvania that wasn't that much money and had this beautiful, like, colonial house on it from like the 1700s. And I was just like, I'm in.

Chris York (33:51):
The market for one of these.

Eliot Gattegno (33:52):
Yeah, exactly. I was like, I wonder how many of these there are out there. Like, this is featured in the Times. So I'm like, I'm sure it's gonna get like snapped up for something. But I see them occasionally and I'm like, huh, there's probably a lot. Maybe I should just go buy one. So my wife and I, we almost didn't for this one in Connecticut a few months back. But I was like, I really, like, want to have my EA run a process because, like, I don't want to go buy the one that's like over here when I could go get the one that's over here. And these are not very much money. And so like, like stuff like that that I'm. I'm sure there's like, very easy ways to do that or quick hacky ways to do that with all the different, like, databases that are available and putting them together and then like, trying to get a little look at trends and like, you know, lowest cost per acre in the United States of like, available land and then like, things like that.

Chris York (34:46):
Yeah, and the other cool thing is it's a perfect example of where the EA doesn't have to know about the subject matter, but, you know, if they knew how to use AI a certain way, it would come up with a list of things that you might consider a checklist where it's like, do they have easements? Is there some litigation against it? Is there a lien on the property? Are there weird zoning things because it's on some sort of protected resource or wildlife or something like that where you couldn't develop it. Right. And without knowing what those things are, they could probably build a really good process that scrapes those listings from whatever and applies a very savvy, you know, you know, land or lot investors, you know, checklist to it, even if they don't know themselves what that should be.

Eliot Gattegno (35:27):
Yeah, that's exactly like the Type of stuff that I think clients, like, they don't even know that those things are possible, so they don't even ask.

Eliot Gattegno (35:35):
Yeah. And like, I literally like, one of my friends, it's a client is a real estate developer and he does like middle rise buildings mostly in Los Angeles and in Southern California, so like 20, 25 story buildings. And he was like looking for potential investors that wanted to buy into one of the funds that he was doing and so on and so forth. And I was like, oh, you should just look at all of the PE firms that own houses in Orange county. Because so many PE firms just like own individual houses and then it's all searchable in California public records, so on and so forth forth. And he was like, oh, shit's gonna take forever. I was like, dude, just get your EA to go through this stuff and like manually click like and go through the fancy neighborhoods and. And he came up with like, he, he raised like, you know, he needed to raise like $50 million like that just like cold calls and different projects from like, you know, got like the best qualified lead list from za. Just doing it manually again can. I'm sure there's a way to automate that from like the SF chronicler data that they've published. And yeah, it's pretty like that's the sort of stuff that like we gotta educate the clients that they can do and then show, like, give the EAs an opportunity to, you know, kind of shine when they're doing it.

Chris York (37:02):
Yeah. And I bet if you go on YouTube right now, somebody has made and built a full like comprehensive tutorial in N8N for like, here's how I find all the single family homes in this area and like have AI draft a message to the actual owner by looking up the MLS records and like scraping their email or something.

Eliot Gattegno (37:22):
Yeah, yeah. Like that is like, that's exactly what I'm talking about doing. So awesome. It seems like first step is to like, you know, get if Carlos is able to share the list or you're able to share the list of different workflows, obviously whatever you're comfortable sharing. And I don't know, like, I mean.

Chris York (37:40):
I can send you a list to the workflows we have right now because we have, we have a workflow that automates the list of workflows. So let me make sure that this is public. Some of them, they might not be fully clear based on the name, but you can definitely see the list of things. A lot of them are agents that are called by other workflows right? So when you start getting advanced at this, it's like, oh, I build a workflow where an AI can go and say look up the venture capital history of a company, right? How many rounds has it had, what's the valuation, who invested and so on. And then you have another workflow that's like scan the GitHub repos. So then it says, oh, when you scan the GitHub repo, if there is a startup associated with it, call the AI that does the research about the funding rounds and then add that to the workflow. And then, you know, you start turning it into kind of like a Lego block system a little bit, right? Where the agent can call the other agent and it's, it's AIs and agents all the way down, right? Running different workflows or calling them conditionally. So yeah, so I sent you the list, the Google sheet. If any of them aren't that clear, I can definitely explain it to you or Carlos can. Carlos can demo you them. He could probably send you a JSON file of it if you want to look how it works, or send you a screenshot if you don't want to get it running on your own stuff. And then, yeah, like whatever else you know, you think makes sense for next steps, I'm sure, you know, we can get you what you need. You know, all our stuff is like pretty well organized and documented for the most part. And if it isn't, then this will help us get it there, which is how I like it to be anyway.

Eliot Gattegno (39:22):
So yeah, so really quick course lesson generator testing. What's that?

Chris York (39:32):
So that one, I ran some courses on behavioral psychology previously, right. And this would do a couple of different things. It would go into a vector database where I have all the papers that I've accumulated over the years and the AI would read the paper and pull out the relevant context based on the topic of the lesson. Right? So say the lesson was about self determination theory. It want to look up papers from, you know, Desi and Ryan and whoever. Right. Then it would also do online research using exa, which is kind of like, think of it as like Google for AIs. Right. There is startup that I happen to invest it in and they make tools for AIs to do better quality research where instead of using keywords, they can use semantic analysis and, and the fancy vector based stuff, right. So then it would do some online research in addition to the papers that I've saved, some of which might be a couple years old. Right. So it's always Got the latest. And then it would go through a workflow of like, finding my previous course material. So the AI knows the structure and the style and the writing of how we're trying to produce and injects all that stuff into the prompts, does the writing, and then does a little loop for editing. Like, does it check this box? Does it check that box? If not, rewrite it and then publish it to webflow. Right, got it.

Eliot Gattegno (41:02):
How fast does it run? Like.

Chris York (41:07):
The web research part takes a couple minutes. The vector database takes about one to two minutes. I would say it takes around five minutes per lesson and it'll consult maybe 25 to 50 PDFs and 10 to 20 website URLs on a given topic.

Eliot Gattegno (41:27):
Yeah, because one of the things that I'm thinking about also for training is like having a series of diagnostics and assessments that people are doing and then trying to get, like, highly personalized learning for wherever they're at and whatever the topic is. And so that's one of, like, it seems like. And like, that was something I was gonna.

Chris York (41:50):
I was gonna do with the next version if I did another course. Obviously I'm busy, so I'm not launching online courses all the time, but I was like, there is no reason that if somebody who is working in the Australian government's behavioral economics team on policy, which is somebody who was in the last course I did, and then somebody else who's working at Apple or working at a startup that does fintech, there's no reason for them to get the same exact material anymore. Right?

Eliot Gattegno (42:10):
Yeah. Yeah. And that's where, for me, that's like Holy Grail type of a thing. And if it's. Yeah. Like, I, I don't mind having people wait for a few minutes for things to be generated. And. Yeah. And then have you seen. And one of the things we were talking in our last board meeting with Sven from the Khosla team, who's like one of the managing.

Chris York (42:37):
The tech guy.

Eliot Gattegno (42:37):
Yeah, yeah. And then he was talking about having, like, AI is generating, like having one model generate, like, basically whatever people are consuming and then having another model kind of doing the assessment of what's going on there. And he, like, he talked about it theoretically, but when I kind of pushed him on how it, like, practically would work, and I got crickets and I emailed him to follow up, to kind of push, and I didn't get anything back. And so I was just, I was wondering if you. If you've been able to solve for that or you've Seen any solves for that practice. So this would be like, you know, you would actually have to be having some sort of an AI that's able to, you know, pick up what's being, you know, done in whatever Google Doc or a sheet or wherever things are being like basically typed and then being able to assess in kind of like that natural environment.

Chris York (43:29):
Yeah, I think there are a lot of good examples of that. Augment is a really good example of an application, their cursor competitor basically, and they do that for code and they have a fancy model that kind of updates the AI through a reinforcement learning system based on behaviorally what edits to the code that you make. Right. So it's kind of studying your patterns of behavior of like what code suggestions you accept from the AI, which ones you reject, how you edit them manually if you do so, and then it kind of updates their AI in the background. So that's a good example of that in other cases. I can give you an example that's really simple which we made. We had a problem with the AI workflow that we had where, you know, you could assign a task in our task manager or you can message them on our chat app and say, hey, find Chris a flight from Bali to Kuala Lumpur next week. Right. And the problem is it doesn't know about what type of flights that I happen to like to take and my preferences. However, if before that you have the AI read all my emails that have flight reservations, then it can develop an sop, and not only an sop, but sort of a checklist and it can return all the flights and then use that checklist to make sure that it's only picking the ones that would conform to the patterns in the past and then also re rank them when you output them. Right. So not a Google Doc, but obviously it's a, it's an output where it's like, here are the flights, these are the ones we think you would like. Here's the, the perks of this one, the red flags. This one, it's a red eye or it's got a long layover or whatever, and using existing data as sort of your revealed preferences, so to speak. Right. And having the AI extract that without the user having to write like, oh, I like this flight if it has a layover, but only if there's a centurion lounge, you know, like they're never going to figure that out. But the AI can grok that from a thousand emails very quickly. And that's a pattern that it would apply to everything it would apply to the way you write your, your docs, transcripts of your meetings, how you run a hiring interview. You know, I had it look at my credit card and my Google Maps starred places and it's like here's the, here's the places you would like to get your hair cut in Seoul based on where you get your haircut in Brooklyn, you know.

Eliot Gattegno (45:44):
Yeah. And how, how accurate are the predictions that you've been seeing?

Chris York (45:51):
Terrifying. Sometimes better than, certainly better than the EA would do themselves unless they've worked with the client for years.

Eliot Gattegno (46:04):
Yeah, that is my, that was my suspicion.

Eliot Gattegno (46:10):
Oh there's like Covey or something coffee shop in Palo Alto. Have you ever been there? Yeah, and so like I've never heard it and I don't know how my EA like found due to whatever coffee shop stuff but obviously it's like not a, like a known known place but it's like oh you're going to love this coffee shop. They have like the great type of coffee that you're going to enjoy, so on and so forth. And I was just like okay when we were there two weeks ago but I went, I was like this is fucking amazing. Espresso. So I was like this is like my style Espresso. I was like nice. How did you, how did you find this and like not go to any of these other places that like I normally would have probably gone. So like yeah I've, I've had like a little bit that I've actually had because I have a very repetitive life because I have a seven month old that I've been barely traveling right now. But be interesting to see when we get it, when we get it out there with more, with more folks.

Eliot Gattegno (47:25):
So cool. I will, I will take a look and then I guess yeah it's going to take a lot of time from you know, probably like Carlos if he can kind of you know, big thing. I think from a client point perspective it's like we've got to get like the problems I think like if we start with the problems that people are trying to solve and then frame like the workflow automation around that and so that, that's kind of how I think about it. But like how would you pitch this stuff to clients? Like you know, we've got to you know, frame it, make it like not super scary for them but like if we want to do like yeah, emailed auto delegators seems super easy like workflow automations. Like like what would be like the normal human language for this workflow automation list? It would just be like, you know, they would be explainable and normal. Like if someone's reading it, like, like I see like, you know, YouTube tool, like, oh, what is that? YouTube tool is a, B and C. It's good for X, Y and Z sort of thing. It solves these different problems.

Chris York (48:16):
Yeah, I mean, I think some of the tools are like, they don't make sense outside of the context of another process that the client has. Right. So, for example, let's just say the client is, you know, running a social media marketing firm. Obviously, you could have an AI that uses the YouTube tool to look up trending topics in that area and then write Twitter posts or something like that. Right. And I bet you A could build that and ADA in like an hour and it would be really good, possibly better writing than the client's previous social media posts. Maybe if they're like a career expert in social media. No, but certainly better than a median person. Right. So, yeah, I mean, I think everybody has workflows. Everybody does work that's repetitive. My work is probably less repetitive than 99% of clients because, like, I have my hands on a lot of different things and I do a lot of weird stuff that is at the bleeding edge of what AI does or whatever. And I'm using hundreds of automations. So if it applies to me and somebody else has a calendar that looks the same exact thing every week, there's much more surface area for them to benefit from this. And I think part of it is not necessarily pitching to clients. It's like the EA can discover what workflows they have. We can also use AI to discover that. So the AI can look at their calendar, it could look at their ats, it could look at their Slack messages or emails and say, hey, here's some processes that you seem to be running that are taking up a lot of time. Right. It's an email thread with 30 replies or it's, you know, 20% of your calendar the last quarter. There's got to be parts of that that we can automate. And I found some examples and some NAN templates, whether they're from, you know, YouTube or Nan's community, or they're from Circle. And we created it ourselves, Right. I think you got to pitch it in reaction to a specific problem. You don't pitch like, oh, workflow automation, this can help us. Right? It's like, oh, you're doing this. Here's how we can automate part of it. Here's how we can put AI into it. And if your EA comes to you with that suggestion, you're like, holy shit. This is a person who's like really trying to like help me out, push the envelope in a way that like an admin traditionally would not do. Right. And where we differentiate ourselves.

Eliot Gattegno (50:29):
Yeah, no, that's, that's exactly where we would like to. Would like to get your opinion on the email auto delegator thing. Like, how long would that take for actually like a member of the tech team to build like the real.

Chris York (50:39):
For real? Well, I think there's a couple of challenges with it, but technically it would take like a day. The challenges with it are, one, people might not want to auto delegate the same way. So the prompt has to be modifiable by the client or by the EA or whoever. The bigger problem is not, is it easy to build something that looks at every email, has the AI review it decides whether there's an action and then creates a task. The problem is mostly people use two email clients, which are Gmail and Outlook, and they right now probably use 10 different task managers. I would assume, right Asana linear todoist Monday. I can name a lot of them and I think if they're not, I've heard that over 50% of people are not even using a task manager with their EA at all. So I had a meeting with Hater about this, actually in person in Palo Alto last quarter, and I said, you got to get clients using a task manager because one, if you're delegating so little shit that you don't even have to use a task manager to like update the status of things, you're probably not delegating well or at a good volume to get the benefit that you're paying for. And the other thing is, without having that, we don't have anything that powers the flywheel, right, where the AI can look at the tasks that you've done in the past and use that to inform how we write tasks to delegate in the future who's doing what. If you have more than one person on your team, right? But obviously you can't have the AI read your email and create a task in the task manager if you don't even use a fucking task manager and you're using like a Google Docs file or you're only emailing tasks your ea, right? So I think a lot of it has to do more with process than anything else. And it may be that we have to support, say, I don't know, four or five task managers to get the 80 or 90% of clients covered, but that's actually not that hard because honestly, if you look at the API and the data structure of Task Manager, they're all basically the fucking same. It's like, title description, comments, priority due date. You know, nobody's got any wild stuff in there that I've seen.

Eliot Gattegno (52:38):
Yeah, but even like, like part of what we're doing is like, if we. Even. So, like, let's say we just made it work for, for like ticktick and we just say, hey, like, our email auto delegator only works with this like, thing to get started. You're thinking that it's really only a day to build something out. And then. Yeah, like with the custom prompting, et cetera, like, so this is not.

Chris York (53:19):
Yeah, I think the prompting is a challenge. Right. Because the issue is people are very heterogeneous. They'll be willing to delegate different things or they'll want to delegate different parts of something. Like, you know, for example, even something as simple as taking a meeting if it's a very important vc, they might want to respond to that email personally and not have their EA respond to it. Another client might be like, EA maximalist. The EA should reply to everything that the EA can possibly reply to. Right. And I will correct it afterwards. And that's the cost of doing business to get the most out of my ea. That's where the devil in the details is. Right. And then also detecting which things are actionable versus not actionable because the AI can get confused. If you get, you know, a spam sales email from somebody and then they think it's important and they create a task for it. But luckily, because we have a EA in the system, they can, you know, course correct it. The risk of a false negative is much more threatening than a false positive in this scenario because we have the human review.

Eliot Gattegno (54:17):
Yeah, yeah, that's, yeah, that's, that all makes sense.

Eliot Gattegno (54:20):
Cool. And then I guess with like the, the lovable stuff, what. Is there anything that, like, you know, that we should know that we should be thinking about?

Chris York (54:33):
There, there's 10 different versions of lovable. There's Bolt New, there's Roark, there's Tempo Labs, and like, honestly, who knows which ones are going to be good? Gemini 2.5 is just as good as any of them. The. The only thing to know is they're good at one shotting stuff from a new idea. They struggle with existing code bases. And if you want to do more advanced stuff, you can create something basic in any of those tools, but then you got to export it to Cursor and You got to do Cursor or you got to use Augment or you got to use Windsurf or whatever, the ones that like, a real software developer would use. So you can only get so far with those app creator tools. And sometimes that's far enough if you want to do something simple, like the website you talked about for Matisse. So you want to do a very basic web app that takes data from point A into point B. You might never need to use Cursor or anything like that at all. But, you know, if you look at Anne's email, she was very meticulous. Like, here's what I did and here's the limits I ran into. So that's the thing. I would feel it's going to be hard to recommend a very specific one for creating stuff. I think Bolt, I would say, is the furthest ahead. Vercell is probably right up there. Lovable is very good. There's a few of them that are More focused on iOS apps or mobile apps in general. I think every EA should be able to use those or use Gemini 2.5 and make a simple app. I don't think necessarily all of them should learn how to use cursor, but for an advanced topic, I think that's a perfectly suitable advanced topic. Because like I said, Anne has no tech background and she shipped an iOS app in like two weeks. Right. So there's probably EAs who have a lot greater familiarity with startups and with coding and product management who could have done even more with that. And as far as picking one cursor is the furthest ahead as far as the UX and things like that right now.

Eliot Gattegno (56:37):
Yeah. That's awesome to think about it. Yeah. For internal stuff, some of the things that I've been thinking is getting them building tools and solutions in this stuff and then sharing them themselves. So, like, again, the more that they can be, like, genuinely doing stuff, the better by comparison to just like, if they're. Yeah, if they're like, learning about these things, I don't want them to learn about them, spend the time learning about them abstractly. I want them to, like, exactly be able to, like, solve the problem for your client. So that's where it's just like, oh, we're going to do a class on like, and do something like unlovable and app development and like, whatever it is. Like, okay, well, like, bring a business challenge that your client is currently facing and, like, let's see how, like, you could maybe surprise and delight them with like, you know, delivering this App and like, whatever or like automating this workflow or whatever, it would be like, that's.

Chris York (57:31):
The stuff that's the key thing. Because like, what I told Ann was like, I'll pay for all the credits you need. You could use any tools that you want. You can generate all the AI artwork you want and make it really cool and have fun with the characters, whatever. But this is done when you write an email explaining what you built and everything works. And there's a test flight link and people can install it on their phone. Right. So that's a very different thing than if you just mess around with it on your computer and it's not going out to anybody. It's like other people have to use it and you're going to have to write an email and share it with people about here's how it works and here's how I built it. So that changes the way you approach everything if you actually have to ship it at the end and with the level of output that you can get from these tools, no matter which one you choose, basically that's a totally reasonable constraint to put on everybody as a forcing function to up the level of output and also like, up their, you know, their level of effort, I think as well.

Eliot Gattegno (58:26):
Yeah. And why was Anne doing this out of curiosity? Like, did you, like, you didn't need to build a to do app. Did you like, for anything or.

Chris York (58:35):
No, certainly not. But, but Jonathan, basically, Jonathan and I, we have discussion sometimes about his, his venture investing and like, I do a little bit of investing as an angel as well. And he was like, yeah, you know, I invest in lovable, I invest in this one, but there's like 20 other ones out there. You know which ones are the best? And I was like, no, I haven't used them personally myself, but I can have Carlos build something here and I have Anne built something here and they'll use a couple of different apps and then we'll get the data back as far as, like, what's working. So with Carlos, I said, hey, I have a really specific idea that I want you to build for Athena, right. I want you to build something where they log in with Gmail and we get an SOP of like their travel and their hotel preferences, their flight preferences, etc. That the AI generates from reading all their emails. Because if, if every EA had that from their clients on day one, obviously they're going to do a much better job. And not only that, that's a great document for an AI to use if you have An AI that can go research hotels, right? And then I. I told him, I was like, here's some UI libraries. Here's the. The ones I want you to use. I told him to use Lovable in that case. And, you know, he was off to the races, right? And then for Anne, I was like, I want you to do something that's a mobile app because I want it to be a different experiment than what Carlos is doing. You can make anything you want. Don't go too crazy, because, you know, if you made like a Unity games, requires like a. A team, you're maybe gonna take a year and a half to ship this thing, right? Which is not what we want. But I was like, you can come up with anything you want as long as it's not too complicated. And it has to be a mobile app and you don't have to use. You can't use Lovable. That's the only rule, right? So we use Bolt. And then she ran into a lot of issues with Bolt, and she exported it to Cursor, and then she became really, really adept with Cursor. So that was the origin of it was we were just wanting to try different tools. Not. Not only to give feedback to Jonathan about, like, you know, the different apps and what's possible, what's not possible, but obviously also, like, what can we train the EAs on, what can we reasonably expect them to be able to achieve with the different tools, how would we train them to use it, et cetera, you know, and honestly, I was not very involved in any of this stuff. Like, it was mostly Carlos and unblocking themselves. Carlos, I basically interacted with almost zero. And then Ann I mostly interacted with just, like, teaching her the basics of product management and how to talk to the AIs and things like that. So.

Eliot Gattegno (1:00:43):
Yep, yep. No, makes sense. That's. That's. That's.

Chris York (1:01:05):
And it's all over chat. I've never spoken. I only speak to her on chat. And Carlos I've spoken with on Zoom twice in the last three years, so.

Eliot Gattegno (1:01:13):
Are you serious?

Chris York (1:01:14):
Yeah.

Eliot Gattegno (1:01:16):
Wow. There's no screen share, there's no live communications. It's all just chat, you know, Send me a screenshot. What's the error? Here's the prompt you used. I'll give you a different prompt. You know, like, that's it.

Eliot Gattegno (1:01:33):
That's amazing. What are you using for chat?

Chris York (1:01:35):
I use Telegram because it's easier to build bots for it than Slack, which you have to pay a lot of money for, and you run into, like, Rate limits. And some of their stuff is a little bit gnarly with the API. So I like Telegram and WhatsApp. You have a really hard time automating a lot of stuff. They make it a living hell, basically.

Eliot Gattegno (1:01:55):
Yeah. Interesting. Oh, that's so funny. I didn't realize that you were that tech space with them. And so that's great.

Eliot Gattegno (1:02:06):
Anything else you should be aware of? As I'm starting to think about this.

Chris York (1:02:13):
Stuff, I think one of the things is the process with Anne in particular, where it's like she can do whatever she wants, but she has somebody she can message to get help from. Most clients, number one, they're not going to be as patient as me because they don't work for Athena. Right. So they're. They're not gonna, like, go the extra mile. They have other things going on and they're not like potentially developing an asset for the company as opposed to just whatever it is that they're trying to do. Right. So I have a very different mindset when I'm collaborating with Ann or Carlos because it can resonate with the other EAs and become operationalized as an asset or a resource in terms of the L and D. Right. And then the other thing is they won't necessarily have the expertise that I have in AI or product. Right. You know, you couldn't expect a client, on average, to give the level of feedback that I'm giving to Anne. Right. So I think one of the things that's really important, again remembering that I never spoke with her. Right. Is like, we can have a couple of people who are just SMEs in AI or in product management, or in lovable cursor, whatever you want to do, workflow, automation, whatever. Right. And it's just somebody that they can message and get help because a lot of the times they could do nine out of the 10 things. And the last thing, it's not necessarily more difficult, but they just don't know how to do it. And it takes more time than all the other things put together. And then it not only blocks them from going forward, but it just like really hurts their morale and their momentum and then it grinds everything to a halt. So I think it would benefit the team a lot if there were different people who had that subject matter expertise who could fill the role that I was filling with Ann that the client is almost certainly not going to fill either from like a time, patience, perspective or expertise standpoint.

Eliot Gattegno (1:04:03):
Yeah, we're starting or we've already started these kind of these expert zones in other areas and it's things like, related to travel and related to like kind of the most frequently asked questions that we've got, like, you know, services. So like I need a, you know, housekeeper in San Francisco on Tuesday and Tuesday I need a pediatrician in, you know, Palo Alto, blah, blah, blah, like those types of things. And then like getting, trying to get referrals so you can, you know, get into places like in just common services and then also be trusted. Definitely agree that it would be great to have somebody in the area of expertise that you're talking about to basically staff that, that stuff.

Chris York (1:04:52):
I mean, honestly, that's more important than the training materials to be, to be honest with you. Right. It's like the best training is like them doing something and being able to finish it and they learn from their experience. Whereas if they, if they read something or they watch a YouTube video or whatever and then they get halfway through and they didn't finish it, then it doesn't matter, you know. And I don't think it would be that expensive for us to resource like a couple of SMEs in these different topics. It's not like people are going to send them a thousand messages a day. Right.

Eliot Gattegno (1:05:21):
Do you, do, you know, like, if you've got any ideas, leads on the types of people, like anything like that, I'd love it if you could send them my way because, you know, we.

Chris York (1:05:31):
Had probably develop them just like have one ea mess around with Nan or mess around with Cursor like for like a couple of months and they'll, you know, they'll, they'll have enough knowledge at that point that they can unblock somebody who's a novice. You know, they don't need to be the best in the world. They just need to be able to unblock like the common beginner obstacles for other people.

Eliot Gattegno (1:05:55):
Yeah, that's, that's, that's, that's like, that's confirming a kind of a hunch because. Did you know Cheryl Nathan's former EMA EA at all?

Chris York (1:06:05):
I, I was on email threads with her. I, I, I don't know her very well.

Eliot Gattegno (1:06:10):
That's exactly like what she's kind of become. So she has become like ultimate, like, you know, dilettante and hacker on these different things. And she was like a STEM elementary school teacher before joining.

Chris York (1:06:22):
Oh, that's perfect.

Eliot Gattegno (1:06:23):
Yeah, and it's great. And so like she's the one, she's like, oh, I'm going to learn how to do. So she was, did that paper that I shared with you. And then like she has done like lots and lots and lots of kind of like hacking and putting together tools. So it's like I need to clone her and you know, clone some Carlos's and Anns and then I feel like that's a sufficient route forward and it did take, you know, a lot of time. Same time it's like my God, what she's doing and like yeah, I would probably pay like someone in the US 20k a month to do what she's doing right now. Easy.

Chris York (1:06:56):
Yeah. And the thing, you know, again like to. So look at Ann, Ann hadn't touched any of these AI tools until two weeks ago. Right. And I guarantee you she can unblock almost anybody on like 90% of the issues that they're going to have shipping their first app because she shipped a pretty good app. And it's, you don't necessarily need somebody with expertise but you do need somebody with the right personality and temperament and interests. So you know, for example, you're saying Cheryl was a former teacher. Right. That you can't teach that like set of interests and that like nurturing personality and like willingness to help people and you know how gratified they are when the, the student succeeds at something. Right. And Anne, you know, doesn't have any react native background but she has a unique talent for like being willing to bang her head into the wall when the AI is like giving her problems about you know, deleting two things for every one, things that it adds and breaking things that were previously working. And you know, and there are certain things like that that I think are really important. You wouldn't need to find like a really good AI person. You just need to find people who have like the willingness to experiment and persevere through some of the roadblocks that come with this stuff and then have the interest and the willingness to teach other people. Right.

Eliot Gattegno (1:08:11):
Yeah, no that's, that's great. Yeah. I think that what I'm going to do is, is a follow up. There's like basic workflows that I would call out in like kind of like sales, marketing operations, et cetera that like are going to be pretty like oh, I want to do that. Like everybody's going to have the email auto delegate. Like the auto delegator is an option like stuff related to calendar research, et cetera. Then there'll be like some. Yeah, just like whether you want to be doing sourcing from a recruiting perspective, like who knows what it would be. But like if we have like these are some generally Recommended workflows or also it's like, I think the. Another major unlock that we would have. It's like, I would always, I would do this in my business if I had someone that was capable of this stuff, but since I don't, I don't. So, you know, and like, that's also like a huge potential value add that we could be going. And so we just need to get stuff like, super off the shelf from a client perspective, make it very clear about the benefit and then what, what they're going to have to put in, what they can expect, how long it's going to take them, et cetera, and then start rolling some of these things out.

Chris York (1:09:24):
Yeah, that makes sense.

Eliot Gattegno (1:09:26):
Cool. Any. Anything else on your mind? You think sharing worth Sharon?

Chris York (1:09:31):
I don't think so. I mean, I think Carlos sent the email of how he built his thing and sent the email on how she built hers. Probably they're not super interested in coaching other people. I don't think they have that, that Cheryl thing. But like I said, I think any, any EA with like, patience and willingness and like, curiosity can become an expert in this stuff. And then you just have to pick the ones who, like, really love showing their work or creating templates for other people or helping other folks, like, get unblocked and stuff like that. And given the volume of people on our talent pool, you know, like, it's inevitable that we have a couple dozen of them, right?

Eliot Gattegno (1:10:07):
Yeah, no, I think there's a, there's a good group. And then it's also. Yeah, the other thing that would be super helpful for me, if you don't mind sharing is like your total tool stack and then like your average amount of money you're spending on this stuff is like, from a client perspective, because that's the other thing. And it can be like, you know, ballpark estimations or something like that. But that's something that Chris Ho is also looking at, is just trying to get partnership deals with all of the different potential vendors that we would work with. And then, you know, if we are saying, like, yeah, to do this stuff, you should have 25 tools and we have like one client that's like spending like two grand a month on all these different things. But they, they swear it's saving them, like all this stuff and their EA is running all these things. So, like, they're probably right. Yeah, like they, they calculated it and it was like, you know, $15,000 or something like that. Like, so, like, for 5,000, I'm getting, you know, what I would pay at least $15,000 for. And this is like pretty fantastic ROI. So it's like the EA plus like 2k's worth of tools that they've paid for for that. So I'm wondering like, what you, if you know, you spend on average with.

Chris York (1:11:27):
I mean, the stuff that, the stuff that I actually do that's relevant to the clients because I do a lot of stuff just for the sake of doing it, to experiment with AI tools. I think it's very affordable. It's definitely less than $50, right? I probably spend $10 a month on like all the AI automations in terms of the automation software, not including the LLM tokens from say OpenAI or Anthropic or Google, that's probably another 20 to 30 bucks as far as core operations as opposed to doing things clients aren't going to do. Have the AI read a thousand biographies and then a couple of tools opportunistically here and there. If I'm doing recruiting, I might pay for an API for LinkedIn where I can scrape people's profiles, and that might be 20 or $50 a month. Right? So if I'm doing something that's for academic research at a high clip, I might pay for Illicit, which is by far the best AI tool for academic research. And they might be $50 a month. Right. But I don't necessarily use it every single month. So I would say on average 50 bucks a month for like core. Core stuff, you know, your AI NoteTaker, your product management app, your LLM credits, your workflow automation, all that and then maybe 100 on the high end. But I think that's about it. I do think that most clients would probably benefit from paying for the $200 a month, deep research like version of OpenAI, because it really does do the best research. And EAs are like a lot more powerful when they can do that, if not only to create the research reports, but to use it as an input to other processes. Right. Lit review, whatever. But they shouldn't have to spend more than 50 or 100 bucks a month for like the core benefits of the majority of the AI work that I do. A lot of the stuff I use, like, it's only relevant to a handful of clients or it's only relevant for a period of aggressive hiring or a period of, you know, some other like, constrained activity like raising venture capital.

Eliot Gattegno (1:13:23):
Yeah, no, that, that's awesome to hear because even like for all the EAs, they have access to our enterprise account now through OpenAI, they get like 50 deep research queries a month. So it's not like unlimited, but it's pretty, it's like almost as good as the 200amonth whatever thing that's there. So they get access to that and they're. And we're working with OpenAI to increase our utilization and stuff. And they're pretty, they've been pretty great. So like, even with that, like all the clients already have access to that. And then if it's not that much more for these other things, that's pretty fantastic. I don't know. What? I don't know. I didn't. I just assumed that you were spending a shitload of money like I said.

Chris York (1:14:06):
I was when I used apir. Because ap, they charge you per thing you automate and that doesn't scale. You know, kudos to them for building a great business. But when we switched to NAN, we hosted it on our own server. We pay $5 a month for the server and $5 a month for the database and it's 10 bucks. So that was a big thing for us. And then also because it's on our own server, there's a little bit better like privacy data stuff. Like I can use a local LLM on my medical record if I wanted to, right?

Eliot Gattegno (1:14:32):
Yeah, yeah. But like, and that's the sort of stuff, it's like, oh, this is how you set up your own server. This is how you set up your own database. Like, that's what we need to get.

Chris York (1:14:40):
And Nathan does have a cloud version and it's not that expensive. It's a lot cheaper than Zapier. But if you're going to use it at a huge clip, no reason to not host it yourself because you could create a guide, but the EA would have it up and running on their own server in like half an hour.

Eliot Gattegno (1:14:58):
Yeah, yeah. I feel like if my like 7 year old son like knows how to do that stuff, our EAs can do that stuff.

Chris York (1:15:03):
Dude, there's YouTube videos and videos on Twitter of like nine year olds. Vibe coding. They're just dictating things to the AI and it's whipping out a full application.

Eliot Gattegno (1:15:13):
You know, it is insane. Like my son is talking to Siri that's connected to OpenAI for all these different things, the questions that they are asking and conversations they're having, it's amazing. And Siri never gets tired and so it's pretty phenomenal.

Eliot Gattegno (1:15:30):
So yeah, I think what's possible with the EAS is going to be. We're in good shape.

Eliot Gattegno (1:15:38):
Cool. Any. Any other stuff or Anything that I should know?

Chris York (1:15:44):
Just whatever you need, feel free to ask. You know, Carlos is usually pretty responsive, and I can give you whatever context that you need on. On any of the other stuff.

Eliot Gattegno (1:15:54):
Yeah, no, I think I'll just go through kind of everything that's. That's in that sheet and then we'll. And then we'll go from there, but should be. That's exciting to kind of get it. Yeah. And if there's, like, other stuff that you're doing that you love with, with Carlos, you know, send it. Send it my way. Be great to see what's replicable, apply, applicable for a bunch of people.

Chris York (1:16:16):
I mean, I think everybody could do it. Like I said, you know, Ann's degree is in hospitality. She didn't work in tech or do any AI stuff before working with me. She's had cursor for two weeks. Carlos is an accountant, you know, by trade, and now he's doing these crazy AI workflows. So I really think anybody can learn. I think anybody who's got the patience or the conscientiousness and stuff, which hopefully we select for in the interview process. There's no reason that the vast majority of EAs can't be doing similar stuff, which is great. I mean, it's a testament to how far the tools have come that we can get this type of output out of, I think, a lot of different people.

Eliot Gattegno (1:16:58):
Yeah, no, very much so. So cool. Well, thanks so much for the time, Chris. I hope you. How long are you in Bali for?

Chris York (1:17:05):
Hopefully another two months.

Eliot Gattegno (1:17:07):
And then where next?

Chris York (1:17:09):
I might go swing by Europe and hang out with Jonathan in Chamonix, or there's some people over there I have to see. I might also go to Japan, so we'll see.

Eliot Gattegno (1:17:19):
Yeah, I mean, you, you, you. I remember last time you were doing summer in Japan, which to me is insane. But you must like it.

Chris York (1:17:24):
Actually, spring, it was the cherry blossoms.

Eliot Gattegno (1:17:29):
Okay. That's when they were. That's when you were there last. All right, well, cool. Well, safe travels wherever you are, and I'll talk to you soon, all right?